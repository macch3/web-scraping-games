{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf5b1e",
   "metadata": {},
   "source": [
    "# Taking reference from https://jovian.com/altamashwaseem04/scraping-top-selling-games-on-steam \n",
    "\n",
    "#### Credits to altamashwaseem04 for the reference script, which formed the basis of this scraping script. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952a115",
   "metadata": {},
   "source": [
    "## Using Selenium webdriver for automation on browsing webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d107d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizing webdriver on selenium to browse webpages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import re #used to import the regular expressions module\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "from bs4 import BeautifulSoup #new import for using BeautifulSoup\n",
    "#Using pandas for dataframe and csv conversion\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e33581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT, DOWNLOAD chromedriver.exe AND PATH IN YOUR LOCAL DEVICE\n",
    "#Specify the path to the directory containing chromedriver.exe\n",
    "webdriver_path = \"Local Device - Path\"\n",
    "\n",
    "# Add the directory to the system PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + webdriver_path\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Use the WebDriver as needed (e.g., navigate to a website)\n",
    "driver.get(\"https://www.example.com\")\n",
    "\n",
    "# Perform your scraping operations\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver creation\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "wd = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial url that we are using\n",
    "url ='https://store.steampowered.com/search/?filter=topsellers'\n",
    "\n",
    "wd.get(url)\n",
    "\n",
    "#Just double checking webdriver is currenctly at the correct page\n",
    "wd.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71243b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create webdriver and downloads page\n",
    "def create_driver(url):\n",
    "  '''Takes the url as an input, creates the webdriver and returns the driver with the page'''\n",
    "  options = webdriver.ChromeOptions()\n",
    "  options.add_argument('--headless')\n",
    "  options.add_argument('--no-sandbox')\n",
    "  options.add_argument('--disable-dev-shm-usage')\n",
    "  wd = webdriver.Chrome(options=options)\n",
    "  wd.get(url)\n",
    "  return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To simulate scrolling through the page\n",
    "import time\n",
    "\n",
    "SCROLL_PAUSE_TIME = 1\n",
    "\n",
    "# Get scroll height\n",
    "last_height = wd.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "for i in range(6):\n",
    "    # Scroll down to bottom\n",
    "    wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = wd.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To simulate scrolling through the page\n",
    "def scroll_page(wd):\n",
    "  '''Takes the driver as an input and simulates the scrolling to get all the games'''  \n",
    "  SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "  # Get scroll height\n",
    "  last_height = wd.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "  for i in range(6):\n",
    "    # Scroll down to bottom\n",
    "    wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = wd.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a0462",
   "metadata": {},
   "source": [
    "## Getting all game titles from Steam Top Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects game titles\n",
    "def get_games(wd):\n",
    "    '''Takes the driver as an input and returns a selenium web element with all the games'''\n",
    "    games_rows = wd.find_element(By.ID, 'search_resultsRows')\n",
    "    games = games_rows.find_elements(By.TAG_NAME, 'a')\n",
    "    return games\n",
    "\n",
    "# Assuming you have initialized the WebDriver as wd\n",
    "\n",
    "# Call the function to get the game elements\n",
    "games = get_games(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed363589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating an empty list\n",
    "games_list = []\n",
    "\n",
    "#looping through all the games\n",
    "for i in range(len(games)): \n",
    "  title =  games[i].find_element(By.CLASS_NAME, 'title').text\n",
    "  game_url = games[i].get_attribute('href')\n",
    "  \n",
    "  #storing the extracted information inside a dictionary\n",
    "  my_game = {\n",
    "      'title': title,\n",
    "      'url': game_url,\n",
    "  }\n",
    "\n",
    "  #adding the dictionary inside the list\n",
    "  games_list.append(my_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5468bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of games in steam's top sellers\n",
    "len(games_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parses web elements and places into games_list with game titles and url\n",
    "def parse_data(games):\n",
    "  '''Takes the web element \"games\" as input and returns a list of dictionary with the title and urls of the games'''\n",
    "  #Creating an empty list\n",
    "  games_list = []\n",
    "\n",
    "  #looping through all the games\n",
    "  for i in range(len(games)): \n",
    "    title =  games[i].find_element_by_class_name('title').text\n",
    "    game_url = games[i].get_attribute('href')\n",
    "    \n",
    "    #storing the extracted information inside a dictionary\n",
    "    my_game = {\n",
    "        'title': title,\n",
    "        'url': game_url,\n",
    "    }\n",
    "\n",
    "    #adding the dictionary inside the list\n",
    "    games_list.append(my_game)\n",
    "  return games_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81c48c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Converts to created list into dataframe \n",
    "gamesdf = pd.DataFrame(games_list)\n",
    "print(gamesdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9af453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(games_list):\n",
    "    '''Takes the list of games as an input, cleans the list of any anomalies and returns its dataframe'''\n",
    "    gamesdf = pd.DataFrame(games_list)\n",
    "    new_gamesdf = gamesdf.copy()  # Initialize new_gamesdf with a copy of the original dataframe\n",
    "    for i in range(len(gamesdf)):\n",
    "        if gamesdf['title'][i] == '' or gamesdf['title'][i] in ['EA Play', 'Valve Index VR Kit', 'Steam Deck', 'Valve IndexÂ® Base Station']:\n",
    "            new_gamesdf.drop(i, inplace=True)\n",
    "    return new_gamesdf\n",
    "\n",
    "new_gamesdf = clean_data(games_list)\n",
    "print(new_gamesdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e805bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe that contains game titles and url links\n",
    "new_gamesdf = clean_data(gamesdf)\n",
    "print(new_gamesdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20861fb4",
   "metadata": {},
   "source": [
    "## Defining functions to enable webdriver to go into each individual url\n",
    "### Script will then extract the relevant information from the webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d059c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skipping age restriction pages\n",
    "def check_page(wd):\n",
    "    '''Takes the driver as an input with a game url and, checks the page and returns the driver'''\n",
    "    try: \n",
    "       try:\n",
    "          info_tag = wd.find_element(By.CLASS_NAME, 'glance_ctn_responsive_left')\n",
    "          return wd\n",
    "       except:\n",
    "          year_tag = wd.find_element(By.CLASS_NAME, 'agegate_birthday_selector')\n",
    "          year = year_tag.find_element(By.ID, 'ageYear')\n",
    "          yearDD = Select(year)\n",
    "          yearDD.select_by_value('1900')\n",
    "          view_button = wd.find_element(By.XPATH, '//*[@id=\"view_product_page_btn\"]')\n",
    "          view_button.click()\n",
    "          time.sleep(4)\n",
    "    except:\n",
    "         return wd\n",
    "\n",
    "    return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd38201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException  # Import the exception\n",
    "\n",
    "def get_price(wd):\n",
    "    '''Takes the driver and returns the original or default price of the game'''\n",
    "\n",
    "    # Check if there's a 'game_purchase_price' appearing before the first instance of 'game_wrapper'\n",
    "    try:\n",
    "        preceding_price_tag = wd.find_element(By.CSS_SELECTOR, '.game_purchase_price')\n",
    "        preceding_price = preceding_price_tag.text.strip()\n",
    "        if preceding_price.lower() == 'free to play' or preceding_price.lower() == 'free':\n",
    "            return preceding_price\n",
    "    except NoSuchElementException:\n",
    "        pass  # Continue to the next step if preceding 'game_purchase_price' is not found\n",
    "\n",
    "    # Check if there's a 'game_purchase_price' or 'discount_original_price'\n",
    "    # by looking for any game_wrapper that contains these elements\n",
    "    game_wrappers = wd.find_elements(By.CSS_SELECTOR, '.game_area_purchase_game_wrapper')\n",
    "    for game_wrapper in game_wrappers:\n",
    "        try:\n",
    "            # Try to extract the price from the 'game_purchase_price' element\n",
    "            price_tag = game_wrapper.find_element(By.CLASS_NAME, 'game_purchase_price')\n",
    "            price = price_tag.text.strip('S$')\n",
    "            return price\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            pass  # Continue to the next game_wrapper if 'game_purchase_price' is not found\n",
    "\n",
    "        try:\n",
    "            # Try to extract the original price from the 'discount_original_price' element\n",
    "            price_tag = game_wrapper.find_element(By.CLASS_NAME, 'discount_original_price')\n",
    "            price = price_tag.text.strip('S$')\n",
    "            return price\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            pass  # Continue to the next game_wrapper if 'discount_original_price' is not found\n",
    "\n",
    "    return 'not available'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discounted(wd, is_free_to_play, price):\n",
    "    '''Takes the driver, a flag indicating if the game is free to play, and the price; returns the discounted price of the game'''\n",
    "\n",
    "    if is_free_to_play or price.lower() in ['free', 'not available']:\n",
    "        return price\n",
    "\n",
    "    try:\n",
    "        # Find the first instance of 'game_area_purchase_game_wrapper'\n",
    "        game_wrapper = wd.find_element(By.CSS_SELECTOR, '.game_area_purchase_game_wrapper')\n",
    "\n",
    "        # Check if the game is part of downloadable content (DLC)\n",
    "        dlc_parent_element = game_wrapper.find_elements(By.CLASS_NAME, 'gameDlcBlocks')\n",
    "\n",
    "        if len(dlc_parent_element) == 0:\n",
    "            try:\n",
    "                # Try to extract the discounted price from the 'discount_final_price' element in the same game wrapper\n",
    "                price_tag = game_wrapper.find_element(By.CLASS_NAME, 'discount_final_price')\n",
    "                disc_price = re.search(r'\\d+\\.\\d+', price_tag.text)\n",
    "                return disc_price.group() if disc_price else 'not available'\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                pass  # Continue to the next step if discounted price is not found\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        pass  # Continue to the next step if game_wrapper is not found\n",
    "\n",
    "    return 'not available'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds release date of game IF available\n",
    "def get_release(wd):\n",
    "   '''Takes the driver and returns the release date of the game'''\n",
    "   try: \n",
    "      info_tag = wd.find_element(By.CLASS_NAME, 'glance_ctn_responsive_left')\n",
    "\n",
    "      release = info_tag.find_element(By.CLASS_NAME, 'release_date').text.strip().replace('RELEASE DATE:\\n','')\n",
    "   except:\n",
    "      release = 'not available'\n",
    "       \n",
    "   return release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acead532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds reviews % of game IF available\n",
    "def get_reviews(wd):\n",
    "  '''Takes the driver and returns the reviews of the game'''\n",
    "  try:  \n",
    "    info_tag = wd.find_element(By.CLASS_NAME, 'glance_ctn_responsive_left')\n",
    "    try:\n",
    "      reviews = info_tag.find_element(By.XPATH, '//*[@id=\"userReviews\"]/div[2]').text.replace('ALL REVIEWS:\\n', '')\n",
    "    except:\n",
    "      reviews = info_tag.find_element(By.CLASS_NAME, 'user_reviews').text.replace('ALL REVIEWS:\\n', '')\n",
    "  except:\n",
    "    reviews = 'not available'\n",
    "  return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7faeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieves genre from page\n",
    "def get_genre_from_html(html):\n",
    "    '''Extract genres from the provided HTML snippet'''\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    genre_b_tag = soup.find('b', text='Genre:')\n",
    "    if genre_b_tag:\n",
    "        span_tag = genre_b_tag.find_next('span')\n",
    "        if span_tag:\n",
    "            genres = [a.text for a in span_tag.find_all('a')]\n",
    "            return ', '.join(genres)\n",
    "    return 'not available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using url found in above dataframe \n",
    "games_url = new_gamesdf['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webdriver will dive into the url link\n",
    "def get_page(url):\n",
    "  '''Takes the url and returns the driver with the page'''\n",
    "  wd.get(url)\n",
    "  return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9490b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webdriver goes into links to find info based on above user defined functions\n",
    "def get_game_info(url):\n",
    "    '''Takes the url and returns a dictionary with the price, discounted price, release date, and the reviews'''\n",
    "    wd_1 = get_page(url)\n",
    "    wd_new = check_page(wd_1)\n",
    "    price = get_price(wd_new)\n",
    "    \n",
    "    # Determine if the game is free to play to pass to get_discounted\n",
    "    is_free_to_play = price.lower() == 'free to play'\n",
    "    \n",
    "    discounted = get_discounted(wd_new, is_free_to_play, price)  # Pass is_free_to_play\n",
    "    release = get_release(wd_new)\n",
    "    reviews = get_reviews(wd_new)\n",
    "    \n",
    "    # Extract the HTML content\n",
    "    html_content = wd_new.page_source\n",
    "\n",
    "    # Get the genre from the HTML content\n",
    "    genre = get_genre_from_html(html_content)\n",
    "    \n",
    "    mygame = {\n",
    "        'price': price,\n",
    "        'discounted_price': discounted,\n",
    "        'release_date': release,\n",
    "        'reviews': reviews,\n",
    "        'genre': genre\n",
    "    }\n",
    "    return mygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a function get_game_info(url) that fetches game information from a URL\n",
    "\n",
    "def get_all_games(games_url):\n",
    "    '''Takes all the urls of the games, creates a list of dictionary of info of the games and returns a dataframe of this'''\n",
    "    game_info_list = []\n",
    "\n",
    "    # Use tqdm to create a progress bar\n",
    "    for i in tqdm(games_url, desc=\"Scraping games\"):\n",
    "        game_info = get_game_info(i)\n",
    "        game_info_list.append(game_info)\n",
    "\n",
    "    game_info_df = pd.DataFrame(game_info_list)\n",
    "    return game_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b5650",
   "metadata": {},
   "source": [
    "## Main scraping script, generating dataframe with all relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS IS THE MAIN BLOCK THAT RETRIEVES ALL INFORMATION. \n",
    "game_info_df = get_all_games(games_url)\n",
    "game_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the DataFrame into three based on columns\n",
    "game_infosplit_df = game_info_df[['release_date', 'reviews']]\n",
    "game_price_df = game_info_df[['price', 'discounted_price']]\n",
    "game_genre_df = game_info_df[['genre']]\n",
    "\n",
    "# Check split works\n",
    "print(game_infosplit_df)\n",
    "print(game_price_df)\n",
    "print(game_genre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49837577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat title and new dataframes together \n",
    "games_info_result = pd.concat([new_gamesdf, game_infosplit_df], axis=1, join='inner')\n",
    "games_info_result.reset_index(drop=True, inplace=True)\n",
    "print(games_info_result)\n",
    "\n",
    "#Concat title and new dataframes together \n",
    "games_price_result = pd.concat([new_gamesdf['title'], game_price_df], axis=1, join='inner')\n",
    "games_price_result.reset_index(drop=True, inplace=True)\n",
    "print(games_price_result)\n",
    "\n",
    "#Concat title and new dataframes together \n",
    "games_genre_result = pd.concat([new_gamesdf['title'], game_genre_df], axis=1, join='inner')\n",
    "games_genre_result.reset_index(drop=True, inplace=True)\n",
    "print(games_genre_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba7cfd",
   "metadata": {},
   "source": [
    "## Converting dataframe into .csv files for further usage\n",
    "### Rename files to preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f59ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating csv file\n",
    "games_info_result.to_csv('games_info' + '.csv', index=False)\n",
    "games_price_result.to_csv('games_price' + '.csv', index=False)\n",
    "games_genre_result.to_csv('games_genre' + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
